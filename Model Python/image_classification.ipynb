{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TY-v-0K89V2"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'animals10:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F59760%2F840806%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240421%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240421T091908Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D5aac2f18f05b5d3fbaf53ad9c0a0796297ed12be2bdd8246bb04df0ebac50593812745599e041cb4e21c8a9a4deb064e80dca7b7e0bf5d2bf9b311498307f727835e3c8b4b57bd26527106e467b334befebfb3cb3efd69d41f94e24cb1edb17e5607c117a9e406dd1d76483eb91ad0f8f04195a3a95ede2be105bd6c5bbe469f1caf985ddb685e4ac0f7e363a5d66d647bb5e26c58e3db9d9afa66760566484537fac165de09e91836870bd15f5ccd4776aa665ab0ace4efc3fc4b32e52880fb6e4e9c1ea05b3c48070cf11a0cd87ddb5ec9506f4466837f10bc40243d805890df7a5e5b456508b6fa9070e3d84b8bfa64f7e77b8bd64b35f3b4ce268d95c803,just-one-cat:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F1203435%2F2011011%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240421%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240421T091908Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D3f3dd5b3bf6f778d3ccce688d2ecfdff8c282105b0f1456859a36f626ce46849cd373428eb95d8ea7c6c44e735ac8c430a5e7c9348000f5340deb4fc4faa1cb06ec846a67e59bcd6fcf50d284312fa754a6d1231ffebb7b63e727d7db942d21b640452e28b3ef0d114d3e906a96499fa2055edf407a9a378f733c57804aadf4cc215a089f8186f65686d011158d159776e696556f9a2e68c7c2103587e7f7531457d246c75ce35f34657bb4a18ea6477b2b1e0e51564d96fa6fb341de36cd893fbb1384a4fef6d9d10d342ce1fb7e3340a0e255965d94bfecbf14fbbffa2c4151f15470815e73074c8103b98d8624aa3c80962343d9a8d85b8afd733251723cf'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-01T10:03:04.043984Z",
          "iopub.status.busy": "2022-02-01T10:03:04.043205Z",
          "iopub.status.idle": "2022-02-01T10:03:04.050052Z",
          "shell.execute_reply": "2022-02-01T10:03:04.049113Z",
          "shell.execute_reply.started": "2022-02-01T10:03:04.043849Z"
        },
        "id": "HWMUb1Xj89V9",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#!pip install --ignore-installed --upgrade tensorflow==2.4.1 --user"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ty6V9p7289V-"
      },
      "source": [
        "Let's import the necessary libraries for this project.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-01T11:02:51.764331Z",
          "iopub.status.busy": "2022-02-01T11:02:51.763902Z",
          "iopub.status.idle": "2022-02-01T11:02:56.322919Z",
          "shell.execute_reply": "2022-02-01T11:02:56.322028Z",
          "shell.execute_reply.started": "2022-02-01T11:02:51.764238Z"
        },
        "id": "vuSUa0uW89V-",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import os\n",
        "import path\n",
        "import pydot\n",
        "from typing import List, Tuple\n",
        "from matplotlib.pyplot import imshow\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import PIL.Image\n",
        "import pathlib\n",
        "import shutil\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "from tensorflow.keras.models import Model, load_model\n",
        "\n",
        "from tensorflow.python.keras.utils import layer_utils\n",
        "#from tensorflow.keras.utils.vis_utils import model_to_dot\n",
        "from tensorflow.keras.utils import model_to_dot\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
        "\n",
        "from IPython.display import SVG\n",
        "\n",
        "import scipy.misc\n",
        "\n",
        "import tensorflow.keras.backend as K\n",
        "K.set_image_data_format('channels_last') # can be channels_first or channels_last.\n",
        "K.set_learning_phase(1) # 1 stands for learning phase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-01T11:02:56.325238Z",
          "iopub.status.busy": "2022-02-01T11:02:56.324689Z",
          "iopub.status.idle": "2022-02-01T11:02:56.337478Z",
          "shell.execute_reply": "2022-02-01T11:02:56.336469Z",
          "shell.execute_reply.started": "2022-02-01T11:02:56.325199Z"
        },
        "id": "Jh16BEJW89WA",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def identity_block(X: tf.Tensor, level: int, block: int, filters: List[int]) -> tf.Tensor:\n",
        "\n",
        "    # layers will be called conv{level}_iden{block}_{convlayer_number_within_block}'\n",
        "    conv_name = f'conv{level}_{block}' + '_{layer}_{type}'\n",
        "\n",
        "    # unpack number of filters to be used for each conv layer\n",
        "    f1, f2, f3 = filters\n",
        "\n",
        "    # the shortcut branch of the identity block\n",
        "    # takes the value of the block input\n",
        "    X_shortcut = X\n",
        "\n",
        "    # first convolutional layer (plus batch norm & relu activation, of course)\n",
        "    X = Conv2D(filters=f1, kernel_size=(1, 1), strides=(1, 1),\n",
        "               padding='valid', name=conv_name.format(layer=1, type='conv'),\n",
        "               kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=conv_name.format(layer=1, type='bn'))(X)\n",
        "    X = Activation('relu', name=conv_name.format(layer=1, type='relu'))(X)\n",
        "\n",
        "    # second convolutional layer\n",
        "    X = Conv2D(filters=f2, kernel_size=(3, 3), strides=(1, 1),\n",
        "               padding='same', name=conv_name.format(layer=2, type='conv'),\n",
        "               kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=conv_name.format(layer=2, type='bn'))(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    # third convolutional layer\n",
        "    X = Conv2D(filters=f3, kernel_size=(1, 1), strides=(1, 1),\n",
        "               padding='valid', name=conv_name.format(layer=3, type='conv'),\n",
        "               kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=conv_name.format(layer=3, type='bn'))(X)\n",
        "\n",
        "    # add shortcut branch to main path\n",
        "    X = Add()([X, X_shortcut])\n",
        "\n",
        "    # relu activation at the end of the block\n",
        "    X = Activation('relu', name=conv_name.format(layer=3, type='relu'))(X)\n",
        "\n",
        "    return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-01T11:02:56.339228Z",
          "iopub.status.busy": "2022-02-01T11:02:56.338848Z",
          "iopub.status.idle": "2022-02-01T11:02:56.35311Z",
          "shell.execute_reply": "2022-02-01T11:02:56.35208Z",
          "shell.execute_reply.started": "2022-02-01T11:02:56.339191Z"
        },
        "id": "rgnRV4wI89WA",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def convolutional_block(X: tf.Tensor, level: int, block: int, filters: List[int], s: Tuple[int,int,int]=(2, 2)) -> tf.Tensor:\n",
        "\n",
        "    # layers will be called conv{level}_{block}_{convlayer_number_within_block}'\n",
        "    conv_name = f'conv{level}_{block}' + '_{layer}_{type}'\n",
        "\n",
        "    # unpack number of filters to be used for each conv layer\n",
        "    f1, f2, f3 = filters\n",
        "\n",
        "    # the shortcut branch of the convolutional block\n",
        "    X_shortcut = X\n",
        "\n",
        "    # first convolutional layer\n",
        "    X = Conv2D(filters=f1, kernel_size=(1, 1), strides=s, padding='valid',\n",
        "               name=conv_name.format(layer=1, type='conv'),\n",
        "               kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=conv_name.format(layer=1, type='bn'))(X)\n",
        "    X = Activation('relu', name=conv_name.format(layer=1, type='relu'))(X)\n",
        "\n",
        "    # second convolutional layer\n",
        "    X = Conv2D(filters=f2, kernel_size=(3, 3), strides=(1, 1), padding='same',\n",
        "               name=conv_name.format(layer=2, type='conv'),\n",
        "               kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=conv_name.format(layer=2, type='bn'))(X)\n",
        "    X = Activation('relu', name=conv_name.format(layer=2, type='relu'))(X)\n",
        "\n",
        "    # third convolutional layer\n",
        "    X = Conv2D(filters=f3, kernel_size=(1, 1), strides=(1, 1), padding='valid',\n",
        "               name=conv_name.format(layer=3, type='conv'),\n",
        "               kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name=conv_name.format(layer=3, type='bn'))(X)\n",
        "\n",
        "    # shortcut path\n",
        "    X_shortcut = Conv2D(filters=f3, kernel_size=(1, 1), strides=s, padding='valid',\n",
        "                        name=conv_name.format(layer='short', type='conv'),\n",
        "                        kernel_initializer=glorot_uniform(seed=0))(X_shortcut)\n",
        "    X_shortcut = BatchNormalization(axis=3, name=conv_name.format(layer='short', type='bn'))(X_shortcut)\n",
        "\n",
        "    # add shortcut branch to main path\n",
        "    X = Add()([X, X_shortcut])\n",
        "\n",
        "    # nonlinearity\n",
        "    X = Activation('relu', name=conv_name.format(layer=3, type='relu'))(X)\n",
        "\n",
        "    return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-01T11:02:59.031277Z",
          "iopub.status.busy": "2022-02-01T11:02:59.030939Z",
          "iopub.status.idle": "2022-02-01T11:02:59.047392Z",
          "shell.execute_reply": "2022-02-01T11:02:59.046509Z",
          "shell.execute_reply.started": "2022-02-01T11:02:59.031243Z"
        },
        "id": "hWRsKo1c89WA",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def ResNet50(input_size: Tuple[int,int,int], classes: int) -> Model:\n",
        "\n",
        "    # tensor placeholder for the model's input\n",
        "    X_input = Input(input_size)\n",
        "\n",
        "    ### Level 1 ###\n",
        "\n",
        "    # padding\n",
        "    X = ZeroPadding2D((3, 3))(X_input)\n",
        "\n",
        "    # convolutional layer, followed by batch normalization and relu activation\n",
        "    X = Conv2D(filters=64, kernel_size=(7, 7), strides=(2, 2),\n",
        "               name='conv1_1_1_conv',\n",
        "               kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "    X = BatchNormalization(axis=3, name='conv1_1_1_nb')(X)\n",
        "    X = Activation('relu')(X)\n",
        "\n",
        "    ### Level 2 ###\n",
        "\n",
        "    # max pooling layer to halve the size coming from the previous layer\n",
        "    X = MaxPooling2D((3, 3), strides=(2, 2))(X)\n",
        "\n",
        "    # 1x convolutional block\n",
        "    X = convolutional_block(X, level=2, block=1, filters=[64, 64, 256], s=(1, 1))\n",
        "\n",
        "    # 2x identity blocks\n",
        "    X = identity_block(X, level=2, block=2, filters=[64, 64, 256])\n",
        "    X = identity_block(X, level=2, block=3, filters=[64, 64, 256])\n",
        "\n",
        "    ### Level 3 ###\n",
        "\n",
        "    # 1x convolutional block\n",
        "    X = convolutional_block(X, level=3, block=1, filters=[128, 128, 512], s=(2, 2))\n",
        "\n",
        "    # 3x identity blocks\n",
        "    X = identity_block(X, level=3, block=2, filters=[128, 128, 512])\n",
        "    X = identity_block(X, level=3, block=3, filters=[128, 128, 512])\n",
        "    X = identity_block(X, level=3, block=4, filters=[128, 128, 512])\n",
        "\n",
        "    ### Level 4 ###\n",
        "    # 1x convolutional block\n",
        "    X = convolutional_block(X, level=4, block=1, filters=[256, 256, 1024], s=(2, 2))\n",
        "    # 5x identity blocks\n",
        "    X = identity_block(X, level=4, block=2, filters=[256, 256, 1024])\n",
        "    X = identity_block(X, level=4, block=3, filters=[256, 256, 1024])\n",
        "    X = identity_block(X, level=4, block=4, filters=[256, 256, 1024])\n",
        "    X = identity_block(X, level=4, block=5, filters=[256, 256, 1024])\n",
        "    X = identity_block(X, level=4, block=6, filters=[256, 256, 1024])\n",
        "\n",
        "    ### Level 5 ###\n",
        "    # 1x convolutional block\n",
        "    X = convolutional_block(X, level=5, block=1, filters=[512, 512, 2048], s=(2, 2))\n",
        "    # 2x identity blocks\n",
        "    X = identity_block(X, level=5, block=2, filters=[512, 512, 2048])\n",
        "    X = identity_block(X, level=5, block=3, filters=[512, 512, 2048])\n",
        "\n",
        "    # Pooling layers\n",
        "    X = AveragePooling2D(pool_size=(2, 2), name='avg_pool')(X)\n",
        "\n",
        "    # Output layer\n",
        "    X = Flatten()(X)\n",
        "    X = Dense(classes, activation='softmax', name='fc_' + str(classes),\n",
        "              kernel_initializer=glorot_uniform(seed=0))(X)\n",
        "\n",
        "    # Create model\n",
        "    model = Model(inputs=X_input, outputs=X, name='ResNet50')\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-01T11:03:02.552611Z",
          "iopub.status.busy": "2022-02-01T11:03:02.552036Z",
          "iopub.status.idle": "2022-02-01T11:03:02.556718Z",
          "shell.execute_reply": "2022-02-01T11:03:02.555624Z",
          "shell.execute_reply.started": "2022-02-01T11:03:02.552577Z"
        },
        "id": "UtiIGcUC89WB",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# set input image parameters\n",
        "image_size = (64, 64)\n",
        "channels = 3\n",
        "num_classes = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-01T11:03:16.976066Z",
          "iopub.status.busy": "2022-02-01T11:03:16.975657Z",
          "iopub.status.idle": "2022-02-01T11:03:20.207862Z",
          "shell.execute_reply": "2022-02-01T11:03:20.20709Z",
          "shell.execute_reply.started": "2022-02-01T11:03:16.976025Z"
        },
        "id": "tSl-PPTb89WB",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model = ResNet50(input_size = (image_size[1], image_size[0], channels), classes = num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.execute_input": "2022-02-01T11:03:20.209752Z",
          "iopub.status.busy": "2022-02-01T11:03:20.209449Z",
          "iopub.status.idle": "2022-02-01T11:03:20.257046Z",
          "shell.execute_reply": "2022-02-01T11:03:20.256327Z",
          "shell.execute_reply.started": "2022-02-01T11:03:20.209718Z"
        },
        "id": "_VW4owV689WB",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-01T11:03:59.405434Z",
          "iopub.status.busy": "2022-02-01T11:03:59.405072Z",
          "iopub.status.idle": "2022-02-01T11:04:03.939632Z",
          "shell.execute_reply": "2022-02-01T11:04:03.938905Z",
          "shell.execute_reply.started": "2022-02-01T11:03:59.405402Z"
        },
        "id": "N42hG6Xp89WC",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# path to desired image set, relative to current working dir\n",
        "in_folder = os.path.join('..', 'input', 'animals10', 'raw-img')\n",
        "\n",
        "file_count = []\n",
        "\n",
        "# get number of images in each folder (images per class)\n",
        "for fld in os.listdir(in_folder):\n",
        "    crt = os.path.join(in_folder, fld)\n",
        "\n",
        "    image_count = len(os.listdir(crt))\n",
        "\n",
        "    file_count.append(image_count)\n",
        "\n",
        "    print(f'{crt} contains {image_count} images')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-01T11:07:00.105076Z",
          "iopub.status.busy": "2022-02-01T11:07:00.10475Z",
          "iopub.status.idle": "2022-02-01T11:07:00.109753Z",
          "shell.execute_reply": "2022-02-01T11:07:00.108568Z",
          "shell.execute_reply.started": "2022-02-01T11:07:00.105045Z"
        },
        "id": "1JzeG05b89WC",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print(f'Total number of images: {sum(file_count)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-01T11:07:04.6861Z",
          "iopub.status.busy": "2022-02-01T11:07:04.685775Z",
          "iopub.status.idle": "2022-02-01T11:07:04.698713Z",
          "shell.execute_reply": "2022-02-01T11:07:04.697889Z",
          "shell.execute_reply.started": "2022-02-01T11:07:04.686068Z"
        },
        "id": "xepbSWqo89WC",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "os.listdir(os.path.join(in_folder, 'elefante'))[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-01T11:07:20.501081Z",
          "iopub.status.busy": "2022-02-01T11:07:20.500766Z",
          "iopub.status.idle": "2022-02-01T11:07:20.559662Z",
          "shell.execute_reply": "2022-02-01T11:07:20.557941Z",
          "shell.execute_reply.started": "2022-02-01T11:07:20.501049Z"
        },
        "id": "T158rplQ89WC",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "data_dir = pathlib.Path(in_folder)\n",
        "\n",
        "elefante = list(data_dir.glob('elefante/*'))\n",
        "\n",
        "PIL.Image.open(str(elefante[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-01T11:07:22.561838Z",
          "iopub.status.busy": "2022-02-01T11:07:22.561525Z",
          "iopub.status.idle": "2022-02-01T11:07:22.567892Z",
          "shell.execute_reply": "2022-02-01T11:07:22.567026Z",
          "shell.execute_reply.started": "2022-02-01T11:07:22.561808Z"
        },
        "id": "J-eSOdm689WC",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "PIL.Image.open(str(elefante[0])).size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-01T11:07:23.240864Z",
          "iopub.status.busy": "2022-02-01T11:07:23.240597Z",
          "iopub.status.idle": "2022-02-01T11:07:23.279959Z",
          "shell.execute_reply": "2022-02-01T11:07:23.279141Z",
          "shell.execute_reply.started": "2022-02-01T11:07:23.240838Z"
        },
        "id": "KYYKcEY589WC",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "PIL.Image.open(str(elefante[10]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-01T11:07:26.299796Z",
          "iopub.status.busy": "2022-02-01T11:07:26.299464Z",
          "iopub.status.idle": "2022-02-01T11:07:26.307042Z",
          "shell.execute_reply": "2022-02-01T11:07:26.305972Z",
          "shell.execute_reply.started": "2022-02-01T11:07:26.299764Z"
        },
        "id": "coNT6FP789WD",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "PIL.Image.open(str(elefante[10])).size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-01T11:09:35.109582Z",
          "iopub.status.busy": "2022-02-01T11:09:35.109123Z",
          "iopub.status.idle": "2022-02-01T11:09:35.113856Z",
          "shell.execute_reply": "2022-02-01T11:09:35.112939Z",
          "shell.execute_reply.started": "2022-02-01T11:09:35.10955Z"
        },
        "id": "Rr4FVBIA89WD",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# path to output folder, relative to current working dir\n",
        "out_folder = os.path.join('..', 'output', 'animals10', 'processed')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OvWH2fkF89WD"
      },
      "source": [
        "Helper function for cropping images into a square."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-01T11:09:35.709969Z",
          "iopub.status.busy": "2022-02-01T11:09:35.70963Z",
          "iopub.status.idle": "2022-02-01T11:09:35.715597Z",
          "shell.execute_reply": "2022-02-01T11:09:35.714765Z",
          "shell.execute_reply.started": "2022-02-01T11:09:35.709943Z"
        },
        "id": "uSVS6vfG89WD",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def square_crop_image(im: PIL.Image) -> PIL.Image:\n",
        "    width, height = im.size\n",
        "    new_size = min(width, height)\n",
        "\n",
        "    # center crop\n",
        "    left = (width - new_size) / 2\n",
        "    top = (height - new_size) / 2\n",
        "    right = (width + new_size) / 2\n",
        "    bottom = (height + new_size) / 2\n",
        "\n",
        "    crop_im = im.crop((left, top, right, bottom))\n",
        "    crop_im = crop_im.convert('RGB')\n",
        "\n",
        "    return crop_im"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-01T11:09:36.044988Z",
          "iopub.status.busy": "2022-02-01T11:09:36.044223Z",
          "iopub.status.idle": "2022-02-01T11:09:36.058194Z",
          "shell.execute_reply": "2022-02-01T11:09:36.057299Z",
          "shell.execute_reply.started": "2022-02-01T11:09:36.044941Z"
        },
        "id": "06R0ZJmA89WH",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "def make_dataset(in_folder, im_per_class):\n",
        "    # iterate through all folders (there should be one folder per object class)\n",
        "    for fld in os.listdir(in_folder):\n",
        "        # create the output folder for processed images for current class\n",
        "        # delete folder and contents if there is one already\n",
        "        out = os.path.join(out_folder, fld)\n",
        "        if os.path.exists(out):\n",
        "            shutil.rmtree(out)\n",
        "        os.makedirs(out)\n",
        "\n",
        "        fld_path = pathlib.Path(os.path.join(in_folder, fld))\n",
        "        num_images = 0\n",
        "        for file in list(fld_path.glob('*')):\n",
        "            # open image, center crop to a square\n",
        "            # save to the output folder\n",
        "            with PIL.Image.open(file) as im:\n",
        "                crop_im = square_crop_image(im)\n",
        "                crop_im.save(os.path.join(out, str(num_images) + '.jpg'))\n",
        "                im.close()\n",
        "            # break when desired number of images\n",
        "            # has been processed (to keep classes balance)\n",
        "            num_images = num_images + 1\n",
        "            if (num_images > im_per_class):\n",
        "                break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-01T11:09:42.158952Z",
          "iopub.status.busy": "2022-02-01T11:09:42.158626Z",
          "iopub.status.idle": "2022-02-01T11:12:58.724762Z",
          "shell.execute_reply": "2022-02-01T11:12:58.723854Z",
          "shell.execute_reply.started": "2022-02-01T11:09:42.15892Z"
        },
        "id": "yAH9JbVb89WH",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# get the number of images that will make our classes balanced\n",
        "im_per_class = min(file_count)\n",
        "\n",
        "# process input images\n",
        "make_dataset(in_folder, im_per_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-01T11:12:58.726826Z",
          "iopub.status.busy": "2022-02-01T11:12:58.726492Z",
          "iopub.status.idle": "2022-02-01T11:12:58.730968Z",
          "shell.execute_reply": "2022-02-01T11:12:58.729811Z",
          "shell.execute_reply.started": "2022-02-01T11:12:58.726793Z"
        },
        "id": "r9MUn-7T89WI",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "img_height = image_size[1]\n",
        "img_width = image_size[0]\n",
        "batch_size = 32"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-01T11:12:58.732792Z",
          "iopub.status.busy": "2022-02-01T11:12:58.732275Z",
          "iopub.status.idle": "2022-02-01T11:12:58.740829Z",
          "shell.execute_reply": "2022-02-01T11:12:58.740172Z",
          "shell.execute_reply.started": "2022-02-01T11:12:58.732757Z"
        },
        "id": "1F-WMrMa89WI",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "data_dir = pathlib.Path(out_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-01T11:12:58.742618Z",
          "iopub.status.busy": "2022-02-01T11:12:58.742135Z",
          "iopub.status.idle": "2022-02-01T11:13:00.581834Z",
          "shell.execute_reply": "2022-02-01T11:13:00.580933Z",
          "shell.execute_reply.started": "2022-02-01T11:12:58.742581Z"
        },
        "id": "iRJZtBnI89WI",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split = 0.2,\n",
        "    subset=\"training\",\n",
        "    label_mode='categorical', # default mode is 'int' label, but we want one-hot encoded labels (e.g. for categorical_crossentropy loss)\n",
        "    seed=123,\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size\n",
        ")\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    data_dir,\n",
        "    validation_split=0.2,\n",
        "    subset=\"validation\",\n",
        "    label_mode='categorical',\n",
        "    seed=123,\n",
        "    image_size=(img_height, img_width),\n",
        "    batch_size=batch_size\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-01T11:13:00.586923Z",
          "iopub.status.busy": "2022-02-01T11:13:00.586571Z",
          "iopub.status.idle": "2022-02-01T11:13:00.599461Z",
          "shell.execute_reply": "2022-02-01T11:13:00.598626Z",
          "shell.execute_reply.started": "2022-02-01T11:13:00.586884Z"
        },
        "id": "IUM_NtsO89WI",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FcOSWYSt89WI"
      },
      "source": [
        "Examine a few processed images before proceesing to the training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-01T11:17:07.294374Z",
          "iopub.status.busy": "2022-02-01T11:17:07.293814Z",
          "iopub.status.idle": "2022-02-01T11:17:08.281988Z",
          "shell.execute_reply": "2022-02-01T11:17:08.281224Z",
          "shell.execute_reply.started": "2022-02-01T11:17:07.294331Z"
        },
        "id": "1XhURvq089WI",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "\n",
        "i = 1\n",
        "\n",
        "for images, labels in train_ds.take(1):\n",
        "    for (image, label) in zip(images, labels):\n",
        "        ax = plt.subplot(4, 4, i)\n",
        "        plt.imshow(image.numpy().astype(\"uint8\"))\n",
        "        plt.title(class_names[tf.argmax(label, axis=0)])\n",
        "        plt.axis(\"off\")\n",
        "        i = i + 1\n",
        "        if i == 17:\n",
        "            break\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceEyrn5689WJ"
      },
      "source": [
        "Cropping was not the best solution, but I'll work with that now.\n",
        "\n",
        "\n",
        "We convert our labels (e.g. right now we have a label of 1 which stands for the class 'cavallo' for example) through one-hot-encoding (our label of 1 from my example thus becomes the array: 0 1 0 0 0 0 0 0 0 0).  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-01T11:18:37.61049Z",
          "iopub.status.busy": "2022-02-01T11:18:37.61012Z",
          "iopub.status.idle": "2022-02-01T11:18:37.660356Z",
          "shell.execute_reply": "2022-02-01T11:18:37.659659Z",
          "shell.execute_reply.started": "2022-02-01T11:18:37.610459Z"
        },
        "id": "bt-3tC0789WJ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# use keras functionality for adding a rescaling layer\n",
        "normalization_layer = layers.experimental.preprocessing.Rescaling(1./255)\n",
        "\n",
        "# rescale training and validation sets\n",
        "norm_train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
        "norm_val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ect_T5ms89WJ"
      },
      "source": [
        "Confirm rescaling results look as expected."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-01T11:18:53.657594Z",
          "iopub.status.busy": "2022-02-01T11:18:53.657276Z",
          "iopub.status.idle": "2022-02-01T11:18:53.829043Z",
          "shell.execute_reply": "2022-02-01T11:18:53.828303Z",
          "shell.execute_reply.started": "2022-02-01T11:18:53.657562Z"
        },
        "id": "JlgHUqWc89WJ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "image_batch, labels_batch = next(iter(norm_train_ds))\n",
        "\n",
        "# get one image\n",
        "first_image = image_batch[0]\n",
        "\n",
        "# confirm pixel values are now in the [0,1] range\n",
        "print(np.min(first_image), np.max(first_image))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvmPlJy189WJ"
      },
      "source": [
        "### 5.2 Model training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rau3b3dW89WJ"
      },
      "source": [
        "First, choose an optimizer schedule, a loss function and metrics to track during training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-01T11:23:59.857379Z",
          "iopub.status.busy": "2022-02-01T11:23:59.857021Z",
          "iopub.status.idle": "2022-02-01T11:23:59.872891Z",
          "shell.execute_reply": "2022-02-01T11:23:59.872058Z",
          "shell.execute_reply.started": "2022-02-01T11:23:59.857346Z"
        },
        "id": "bi5NtsHj89WJ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer='adam', # optimizer\n",
        "    loss='categorical_crossentropy', # loss function to optimize\n",
        "    metrics=['accuracy'] # metrics to monitor\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7EF3rnkB89WJ"
      },
      "source": [
        "Configure the dataset for performance by enabling prefetching. Read more <a href=\"https://www.tensorflow.org/guide/data_performance\">here</a>."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-01T11:24:00.575043Z",
          "iopub.status.busy": "2022-02-01T11:24:00.574723Z",
          "iopub.status.idle": "2022-02-01T11:24:00.584778Z",
          "shell.execute_reply": "2022-02-01T11:24:00.583846Z",
          "shell.execute_reply.started": "2022-02-01T11:24:00.575012Z"
        },
        "id": "l0tq9IXU89WJ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "norm_train_ds = norm_train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "norm_val_ds = norm_val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kd0QcNrn89WK"
      },
      "source": [
        "Run the following cell to train your model on 2 epochs with a batch size of 32. We also use this to see how long it takes to train for one epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-01T11:24:01.363325Z",
          "iopub.status.busy": "2022-02-01T11:24:01.363012Z",
          "iopub.status.idle": "2022-02-01T11:24:37.034048Z",
          "shell.execute_reply": "2022-02-01T11:24:37.033363Z",
          "shell.execute_reply.started": "2022-02-01T11:24:01.363294Z"
        },
        "id": "3EucVzoS89WK",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "start = time.time()\n",
        "\n",
        "model.fit(\n",
        "    norm_train_ds,\n",
        "    validation_data=norm_val_ds,\n",
        "    epochs = 2)\n",
        "\n",
        "stop = time.time()\n",
        "\n",
        "print(f'Training took: {(stop-start)/60} minutes')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1BZkhp189WK"
      },
      "source": [
        "On my laptop, training for two epochs takes a huge amount of time. Even after half an hour of training, the accuracy on the training set is 24%, which is of course not acceptable in a real world scenario.\n",
        "\n",
        "On Kaggle, on a CPU, training takes even longer than on my personal laptop. Kaggle CPU is very very slow.\n",
        "\n",
        "So we'll have to activate Kaggle's GPU and retrain. In the next section we'll see how."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKb6yqzi89WK"
      },
      "source": [
        "# 6. Training the ResNet model on Kaggle GPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZApG6t9W89WK"
      },
      "source": [
        "Configure the model like before."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-01T11:24:52.016315Z",
          "iopub.status.busy": "2022-02-01T11:24:52.015938Z",
          "iopub.status.idle": "2022-02-01T11:24:52.906704Z",
          "shell.execute_reply": "2022-02-01T11:24:52.905966Z",
          "shell.execute_reply.started": "2022-02-01T11:24:52.016276Z"
        },
        "id": "9yAXEd5R89WK",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model_on_gpu = ResNet50(input_size = (image_size[1], image_size[0], channels), classes = num_classes)\n",
        "model_on_gpu.compile(\n",
        "    optimizer='adam', # optimizer\n",
        "    loss='categorical_crossentropy', # loss function to optimize\n",
        "    metrics=['accuracy'] # metrics to monitor\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jJ-19Kv89WK"
      },
      "source": [
        "Make sure we have enabled the GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-01T11:24:52.90851Z",
          "iopub.status.busy": "2022-02-01T11:24:52.908166Z",
          "iopub.status.idle": "2022-02-01T11:24:52.917709Z",
          "shell.execute_reply": "2022-02-01T11:24:52.916892Z",
          "shell.execute_reply.started": "2022-02-01T11:24:52.908483Z"
        },
        "id": "ixv11Ooz89WK",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if \"GPU\" not in device_name:\n",
        "    print(\"GPU device not found\")\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bap0dmgV89WK"
      },
      "source": [
        "We use a callback to stop the training process when the accuracy is no longer improving."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-01T11:24:55.023941Z",
          "iopub.status.busy": "2022-02-01T11:24:55.023595Z",
          "iopub.status.idle": "2022-02-01T11:24:55.029411Z",
          "shell.execute_reply": "2022-02-01T11:24:55.028213Z",
          "shell.execute_reply.started": "2022-02-01T11:24:55.023906Z"
        },
        "id": "S0rpT3f489WL",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "callbacks = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\", # monitor validation loss (that is, the loss computed for the validation holdout)\n",
        "        min_delta=1e-2, # \"no longer improving\" being defined as \"an improvement lower than 1e-2\"\n",
        "        patience=10, # \"no longer improving\" being further defined as \"for at least 10 consecutive epochs\"\n",
        "        verbose=1\n",
        "    )\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bi7exWOk89WL"
      },
      "source": [
        "Train the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-01T11:24:56.966285Z",
          "iopub.status.busy": "2022-02-01T11:24:56.96595Z",
          "iopub.status.idle": "2022-02-01T11:32:23.243797Z",
          "shell.execute_reply": "2022-02-01T11:32:23.242925Z",
          "shell.execute_reply.started": "2022-02-01T11:24:56.966249Z"
        },
        "id": "SJsBx3lz89WL",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "start = time.time()\n",
        "with tf.device('/gpu:0'):\n",
        "    history = model_on_gpu.fit(\n",
        "        norm_train_ds,\n",
        "        validation_data=norm_val_ds,\n",
        "        epochs=40,\n",
        "        callbacks=callbacks,\n",
        "    )\n",
        "stop = time.time()\n",
        "print(f'Training on GPU took: {(stop-start)/60} minutes')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjaE3qmK89WL"
      },
      "source": [
        "Let's have a look at how our metrics progressed across epochs for training and validation sets.  \n",
        "We examine both accuracy and loss to see if we can draw any interesting conclusions out of it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-01T11:49:49.208028Z",
          "iopub.status.busy": "2022-02-01T11:49:49.207702Z",
          "iopub.status.idle": "2022-02-01T11:49:49.472536Z",
          "shell.execute_reply": "2022-02-01T11:49:49.471675Z",
          "shell.execute_reply.started": "2022-02-01T11:49:49.207995Z"
        },
        "id": "_uCbJpjR89WL",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print(history.history.keys())\n",
        "\n",
        "plt.figure(figsize=(12, 10))\n",
        "\n",
        "# summarize history for accuracy\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "\n",
        "# summarize history for loss\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLtUAlNO89WL"
      },
      "source": [
        "# 7. Making predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMReRghD89WL"
      },
      "source": [
        "### 7.1 Let's evaluate our model on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-01T11:50:25.149289Z",
          "iopub.status.busy": "2022-02-01T11:50:25.148847Z",
          "iopub.status.idle": "2022-02-01T11:50:26.45472Z",
          "shell.execute_reply": "2022-02-01T11:50:26.453599Z",
          "shell.execute_reply.started": "2022-02-01T11:50:25.149246Z"
        },
        "id": "93C7EifM89WM",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "#preds = model_on_gpu.evaluate(X_test, Y_test)\n",
        "preds = model_on_gpu.evaluate(norm_val_ds)\n",
        "print (\"Loss = \" + str(preds[0]))\n",
        "print (\"Test Accuracy = \" + str(preds[1]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDZWnRDf89WM"
      },
      "source": [
        "### 7.2 Let's try a new, unseen image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-01T11:50:47.111132Z",
          "iopub.status.busy": "2022-02-01T11:50:47.110814Z",
          "iopub.status.idle": "2022-02-01T11:50:47.282213Z",
          "shell.execute_reply": "2022-02-01T11:50:47.281353Z",
          "shell.execute_reply.started": "2022-02-01T11:50:47.111101Z"
        },
        "id": "toD7go8x89WM",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "\n",
        "test_img_path = '../input/just-one-cat/cat_1.jpg'\n",
        "\n",
        "# read image\n",
        "img = cv2.imread(test_img_path)\n",
        "\n",
        "# reorder RGB channels (opencv reads as BGR by default)\n",
        "RGB_img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# resize to the same input image size that we used when defining the model architecture\n",
        "x = cv2.resize(RGB_img, image_size, interpolation = cv2.INTER_AREA)\n",
        "\n",
        "print('Input image shape:', x.shape) # sanity check\n",
        "\n",
        "plt.imshow(RGB_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-01T11:52:13.195413Z",
          "iopub.status.busy": "2022-02-01T11:52:13.195045Z",
          "iopub.status.idle": "2022-02-01T11:52:14.175302Z",
          "shell.execute_reply": "2022-02-01T11:52:14.174511Z",
          "shell.execute_reply.started": "2022-02-01T11:52:13.195381Z"
        },
        "id": "s6tnFoRh89WM",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "x = np.expand_dims(x, axis=0) # fake batch size dimension\n",
        "x = x/255.0 # normalize pixel values to [0,1] interval\n",
        "\n",
        "preds = model_on_gpu.predict(x) # get model predictions\n",
        "\n",
        "print(\"Model's prediction has this format: [p(0), p(1), ... , p(5)] = \")\n",
        "print(preds)\n",
        "\n",
        "\n",
        "\n",
        "print(\"The prediction for this image is: \", class_names[np.argmax(preds)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-01T11:54:30.980015Z",
          "iopub.status.busy": "2022-02-01T11:54:30.979697Z",
          "iopub.status.idle": "2022-02-01T11:54:30.98722Z",
          "shell.execute_reply": "2022-02-01T11:54:30.986231Z",
          "shell.execute_reply.started": "2022-02-01T11:54:30.979983Z"
        },
        "id": "psiDsYRI89WM",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "len(preds[0])\n",
        "\n",
        "for i, p in enumerate(preds[0]):\n",
        "    print(f'p:{p:.05f}\\t{class_names[i]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MubtklgZ89WM"
      },
      "source": [
        "# 8. Overfitting when training our Residual Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKveubv589WM"
      },
      "source": [
        "In the previous section, we used Keras Callbacks to stop training at the optimum number of epochs: when the loss for the validation set was no longer improving.  \n",
        "\n",
        "The stopping happened very early in the training. Why do you think that happened ? Have a look at the images we used from 10 different classes, take a look at our model's structure and try to compute the number of parameters the network has to learn through training. Please leave your comments below regarding what can be the cause of our model not learning anymore after only a a couple of epochs. I believe this discussion is quite beneficial to our learning process.  \n",
        "\n",
        "Now, what happens if I decide not to stop training at epoch < 10 ? I want to see what I end up with if I keep training for 100 epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-01T11:55:51.368198Z",
          "iopub.status.busy": "2022-02-01T11:55:51.367863Z",
          "iopub.status.idle": "2022-02-01T12:06:06.308706Z",
          "shell.execute_reply": "2022-02-01T12:06:06.307901Z",
          "shell.execute_reply.started": "2022-02-01T11:55:51.368152Z"
        },
        "id": "ZHXPE3VP89WN",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "model_on_gpu_40e = ResNet50(input_size = (image_size[1], image_size[0], channels), classes = len(class_names))\n",
        "\n",
        "model_on_gpu_40e.compile(\n",
        "    optimizer='adam', # optimizer\n",
        "    loss='categorical_crossentropy', # loss function to optimize\n",
        "    metrics=['accuracy'] # metrics to monitor\n",
        ")\n",
        "\n",
        "start = time.time()\n",
        "with tf.device('/gpu:0'):\n",
        "    history = model_on_gpu_40e.fit(\n",
        "        norm_train_ds,\n",
        "        validation_data=norm_val_ds,\n",
        "        epochs=40,\n",
        "        #batch_size=64,\n",
        "    )\n",
        "stop = time.time()\n",
        "\n",
        "print(f'Training for 40 epochs on GPU took: {(stop-start)/60} minutes')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2022-02-01T12:06:06.311831Z",
          "iopub.status.busy": "2022-02-01T12:06:06.311466Z",
          "iopub.status.idle": "2022-02-01T12:06:06.648345Z",
          "shell.execute_reply": "2022-02-01T12:06:06.647251Z",
          "shell.execute_reply.started": "2022-02-01T12:06:06.311796Z"
        },
        "id": "jnVWQmMd89WN",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "print(history.history.keys())\n",
        "\n",
        "plt.figure(figsize=(12, 10))\n",
        "\n",
        "# summarize history for accuracy\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "\n",
        "# summarize history for loss\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
